# Interactive Visual Reinforcement Learning on Atari's Breakout
#### A CS-8395 Project (WIP)

This project intends to address challenges with understanding complex reinforcement learning agents on complicated tasks like Atari games through visual aids.  

### Baseline Update
This baseline consists of serving sample saliency maps based on input of two main sliders. The first slider denotes the frame number of an episode at rollout. The second slider denotes the model being rolled-out, specified by the total number of frames the model used for training. The environment frame is displayed with perturbation-based saliency as specified in [the baseline paper](https://arxiv.org/abs/1711.00138). 

**Instructions:**
To run the dashboard:
```
python app.py # localhost:8050
```

To train a new model:
```
cd baby-a3c
python baby-a3c.py --load_model <model name> 

python baby-a3c.py --load_model <old model name> # to continue training on an older model
```

To get saliency maps:
```
jupyter notebook
-> visualize_atari/jacobian-vs-perturbation.ipynb
```
This notebook also provides support for saving rollout data and saliency maps. Rollout data is generated by iterating through all saved models, running each model on an episode (random seed 1), and capturing data for all steps. See `visualize_atari/rollout.py`. Data captured consists of:

- Environment state (image as np array)
- Hidden state of GRU cell 
- Logits 
- Values 
- output (probability over actions)


Presentation in `assets/VAML Baseline.pdf`


**Environment:**
- Python 3.6
- PyTorch 1.0 
- [Dash](https://dash.plot.ly/installation)

# References/Source Material
Code adapted from Sam Greydanus' work:

https://github.com/greydanus/visualize_atari - generate saliency maps of agent playthroughs
https://github.com/greydanus/baby-a3c - for a3c model training 
https://arxiv.org/abs/1711.00138 

MIT License
